{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b42a881",
   "metadata": {},
   "source": [
    "# Image Processing End of Term Project\n",
    "# Gate Access Controller Using License Plate Detection and OCR\n",
    "# Team 14\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72bb591e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\nadin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\nadin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\nadin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\nadin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\nadin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\nadin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\nadin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\nadin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\nadin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\nadin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\nadin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\nadin\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python==4.5.4.60 in c:\\users\\nadin\\anaconda3\\lib\\site-packages (4.5.4.60)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\nadin\\anaconda3\\lib\\site-packages (from opencv-python==4.5.4.60) (1.21.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install opencv-python==4.5.4.60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6a96b33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenCV version:  4.5.4\n"
     ]
    }
   ],
   "source": [
    "###Imports\n",
    "\n",
    "# Preprocessing and chaarcter recognition modules\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.exposure import histogram\n",
    "from matplotlib.pyplot import bar\n",
    "from skimage.color import rgb2gray,rgb2hsv\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy import signal as sig\n",
    "from scipy.signal import convolve2d\n",
    "from scipy import fftpack\n",
    "import math\n",
    "from skimage.util import random_noise\n",
    "from skimage.filters import median\n",
    "from skimage.feature import canny\n",
    "from skimage.measure import label\n",
    "from skimage.filters import threshold_local\n",
    "from skimage.color import label2rgb\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.morphology import skeletonize\n",
    "import imutils\n",
    "from skimage import measure\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import easyocr\n",
    "import PySimpleGUI as sg\n",
    "from PIL import Image, ImageTk\n",
    "#import pkg_resources\n",
    "#pkg_resources.require('OpenCV==4.5.4.60')\n",
    "import cv2\n",
    "print('OpenCV version: ', cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c88c2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b221d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to display images\n",
    "def show_images(images,titles=None):\n",
    "    n_ims = len(images)\n",
    "    if titles is None: titles = ['(%d)' % i for i in range(1,n_ims + 1)]\n",
    "    fig = plt.figure()\n",
    "    n = 1\n",
    "    for image,title in zip(images,titles):\n",
    "        a = fig.add_subplot(1,n_ims,n)\n",
    "        if image.ndim == 2: \n",
    "            plt.gray()\n",
    "        plt.imshow(image)\n",
    "        a.set_title(title)\n",
    "        n += 1\n",
    "    fig.set_size_inches(np.array(fig.get_size_inches()) * n_ims)\n",
    "    plt.show() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6688ee73",
   "metadata": {},
   "source": [
    "# Preprocessing step\n",
    "\n",
    "#### 1. First we resize image for preprocessing to be same for all images\n",
    "#### 2. We Convert to gray scale and using bilateral filter to eliminate noise, as it is more effectve than median filter \n",
    "#### 3. Next we use Canny edge detector to extract edges because has good localization, it extract image features without altering the image features and it is less sensitive to noise\n",
    "#### 4. Create a mask for the contour only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "168fea0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different noise eliminating filters\n",
    "\n",
    "def MedianFilter(image):\n",
    "    return median(img)\n",
    "\n",
    "def BilateralFilter(image):\n",
    "    return cv2.bilateralFilter(image, 11, 17, 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91ee9aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(image):\n",
    "    #Handling corner case of image not exists\n",
    "    if image is None: \n",
    "        print('This image does not exist.')\n",
    "        return None, None, 0, 0, 0, 0, None\n",
    "    \n",
    "    cv2.resize(image,(int(image.shape[0]),int(500)))\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    gray_filtered = cv2.bilateralFilter(gray, 11, 17, 17)\n",
    "    edged=cv2.Canny(gray_filtered,170,200)\n",
    "    \n",
    "    # Finding enclosed areas which is the license plate  we get contours of minimum size 10\n",
    "    keypoints = cv2.findContours(edged.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = imutils.grab_contours(keypoints)\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)[:10]\n",
    "\n",
    "    # We store te location of the largest contour found in our image\n",
    "    # we know it's the largest since we sort contours using the contour area\n",
    "    location = None\n",
    "    # No contour of minimum size 10 found\n",
    "    if len(contours) == 0: return None, None, 0, 0, 0, 0, None\n",
    "    for contour in contours:\n",
    "        approx = cv2.approxPolyDP(contour, 10, True)\n",
    "        # Retrieve contours with 4 vertices, therefore rectangular, if found break\n",
    "        if len(approx) == 4:\n",
    "            location = approx\n",
    "            x,y,w,h = cv2.boundingRect(contour)\n",
    "            break\n",
    "    \n",
    "    # Contour location might not be found so handle if none\n",
    "    if location is None: return None, None, 0, 0, 0, 0, None\n",
    "    \n",
    "    # We create a black image of all zeros to draw contour found on \n",
    "    mask = np.zeros(gray_filtered.shape, np.uint8)\n",
    "    drawCont = cv2.drawContours(mask, [location], 0,255, -1)\n",
    "    Masked = cv2.bitwise_and(image, image, mask = mask)\n",
    "    \n",
    "   \n",
    "    # Returns the plate region processed, the x,y coordinates of the plate, the width and heigh of the region\n",
    "    # and finally the masked image before ccropping into plateRegionOnly\n",
    "    #----------\n",
    "    mask = np.zeros(gray.shape, np.uint8)\n",
    "    if location is None: return None, None, 0, 0, 0, 0, None\n",
    "    new_image1 = cv2.drawContours(mask, [location], 0,255, -1)\n",
    "    new_image2 = cv2.bitwise_and(image, image, mask=mask)\n",
    "    \n",
    "    ############################################ Step 2 -> Plate Enhancement\n",
    "    #SE_Size=100\n",
    "    kernel =cv2.getStructuringElement(cv2.MORPH_RECT,(3,3))\n",
    "\n",
    "    #extractedPlate = cv2.erode(new_image2,kernel,iterations = 1)\n",
    "    #img_erosion = cv2.erode(img, kernel, iterations=1)\n",
    "    #img_dilation = cv2.dilate(extractedPlate, kernel, iterations=2)\n",
    "    \n",
    "    plateRegionOnly = new_image2[y:y+h, x:x+w ]\n",
    "    gray2 = cv2.cvtColor(plateRegionOnly, cv2.COLOR_RGB2GRAY)\n",
    "    done = cv2.bilateralFilter(gray2, 11, 17, 17)\n",
    "    #show_images([plateRegionOnly, Masked, new_image2, new_image1, done])\n",
    "\n",
    "    return plateRegionOnly, location, x, y, w, h, Masked\n",
    "\n",
    "#readImage = cv2.imread(pathAsStr+str(0)+'.png')\n",
    "#plateRegionOnly, location, x, y, w, h, Masked = preprocessing(readImage)\n",
    "#show_images([RegionOfInterest(plateRegionOnly, location, x, y, w, h)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0185de",
   "metadata": {},
   "source": [
    "### This function is a customizable preprocessing function\n",
    "### we can send it a list of 0s and 1's where 0 means erode and 1 means dilate and we pass the image through\n",
    "### these as sent in order e.g. [0, 1, 1, 0] means an erossion, 2 dilations, and an erosion again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e4afd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def customizablePreprocessing(image, seqOfErodDil, sizeStructElement):\n",
    "    #Handling corner case of image not exists\n",
    "    \n",
    "    if image is None: \n",
    "        print('This image does not exist.')\n",
    "        return None, None, 0, 0, 0, 0, 0\n",
    "    \n",
    "    cv2.resize(image,(int(image.shape[0]),int(500)))\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    gray_filtered = cv2.bilateralFilter(gray, 11, 17, 17)\n",
    "    edged=cv2.Canny(gray_filtered,170,200)\n",
    "    \n",
    "    # Finding enclosed areas which is the license plate  we get contours of minimum size 10\n",
    "    keypoints = cv2.findContours(edged.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = imutils.grab_contours(keypoints)\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)[:10]\n",
    "\n",
    "    # We store te location of the largest contour found in our image\n",
    "    # we know it's the largest since we sort contours using the contour area\n",
    "    location = None\n",
    "    # No contour of minimum size 10 found\n",
    "    if len(contours) == 0: return None, None, 0, 0, 0, 0, 0\n",
    "    for contour in contours:\n",
    "        approx = cv2.approxPolyDP(contour, 10, True)\n",
    "        # Retrieve contours with 4 vertices, therefore rectangular, if found break\n",
    "        if len(approx) == 4:\n",
    "            location = approx\n",
    "            x,y,w,h = cv2.boundingRect(contour)\n",
    "            break\n",
    "    # Contour location might not be found so handle if none\n",
    "    if location is None: return None, None, 0, 0, 0, 0 , 0\n",
    "    \n",
    "    # We create a black image of all zeros to draw contour found on \n",
    "    mask = np.zeros(gray.shape, np.uint8)\n",
    "    drawCont = cv2.drawContours(mask, [location], 0,255, -1)\n",
    "    Masked = cv2.bitwise_and(image, image, mask = mask)\n",
    "    \n",
    "    if seqOfErodDil is None: \n",
    "        return plateRegionOnly, location, x, y, w, h, Masked\n",
    "    \n",
    "    # else create our kernel\n",
    "    kernel =cv2.getStructuringElement(cv2.MORPH_RECT,(sizeStructElement,sizeStructElement))\n",
    "    lastImge = Masked\n",
    "    for j in seqOfErodDil:\n",
    "        if j == 0:\n",
    "            morphology = cv2.erode(lastImge, kernel, iterations=1)\n",
    "        else:\n",
    "            morphology = cv2.dilate(extractedPlate, kernel, iterations=1)\n",
    "        lastImge = morphology\n",
    "    \n",
    "    plateRegionOnly = lastImge[y:y+h, x:x+w ]\n",
    "    return plateRegionOnly, location, x, y, w, h, lastImge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cc36b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Archived function because \n",
    "# 1. Causes error in some images \n",
    "# 2. Tilts are so slight and we assume camera position fitted to see plate in correct position\n",
    "# 3. Even tilted iimages not affected by rotations\n",
    "\n",
    "def RotateTilted(extractedPlate, location):\n",
    "    left_bottom =  location[3][0]\n",
    "    right_bottom = location[0][0]\n",
    "    left_top =  location[2][0]\n",
    "    right_top = location[1][0]\n",
    "    xEnd = max(right_top[0],right_bottom[0]) + 20\n",
    "    yEnd = min(right_bottom[1],left_bottom[1]) + 10\n",
    "    plateRegionOnly = extractedPlate[yEnd:left_top[1]+10,left_bottom[0]-20:xEnd ]\n",
    "    print(yEnd, left_top[1],left_bottom[0]-20,xEnd)\n",
    "    hypotenuse =  math.pow((math.pow((left_bottom[0]-right_bottom[0]), 2) + math.pow((left_bottom[1]-right_bottom[1]), 2)), 0.5)\n",
    "    opposite = right_bottom[1] - left_bottom[1]\n",
    "    rotationAngle = math.asin(opposite/hypotenuse)*57.2958\n",
    "    rotated = imutils.rotate_bound(plate, angle=-rotationAngle)\n",
    "    return rotated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6e61d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RegionOfInterest(plate,location,x,y,w,h):    \n",
    "    gray = cv2.cvtColor(plate, cv2.COLOR_BGR2GRAY)\n",
    "    # Get The Thresholding TODO:get another\n",
    "    gray = cv2.resize(gray, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
    "    gray = cv2.medianBlur(gray, 3)\n",
    "    GlobalThresh = threshold_otsu(gray)\n",
    "    ThreshImage = np.copy(gray)\n",
    "    ThreshImage[gray >= GlobalThresh] = 0\n",
    "    ThreshImage[gray < GlobalThresh] = 1\n",
    "    Parition = np.copy(ThreshImage)\n",
    "    Binary = np.copy(plate)\n",
    "    Parition = cv2.medianBlur(Parition, 3)\n",
    "    return Parition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a372a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function segments characters by finding contours around character\n",
    "def segmnetCharactersByContours(plate):\n",
    "    copy=np.copy(plate)\n",
    "    cnts = cv2.findContours(plate, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "    charsSegmented = []\n",
    "    ROI_number = 0\n",
    "    for c in cnts:\n",
    "        x,y,w,h = cv2.boundingRect(c)\n",
    "        ROI = plate[y:y+h, x:x+w]\n",
    "        resizing = imutils.resize(ROI, width=200)\n",
    "        charsSegmented.append(ROI)\n",
    "        cv2.imwrite('result/ROI_{}.png'.format(ROI_number), 255*resizing)\n",
    "        ROI_number += 1\n",
    "    return charsSegmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c077e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmnetCharactersByContours2(image):\n",
    "    copy=np.copy(image)\n",
    "    all_imgs=[] #to sort charchters as in the input image #imge,startingx,width\n",
    "    cnts = cv2.findContours(image, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "    cnts = sorted(cnts, key = cv2.contourArea, reverse = True) #discard first two detected imaged\n",
    "    charsSegmented = []\n",
    "    ROI_number = 0\n",
    "    i=0\n",
    "    #print(cnts)\n",
    "    for c in cnts:\n",
    "        x,y,w,h = cv2.boundingRect(c)\n",
    "        outside = True\n",
    "        if i < 2:\n",
    "                ROI = image[y:y+h, x:x+w]\n",
    "                resizing = imutils.resize(ROI, width=200)\n",
    "                charsSegmented.append(ROI)\n",
    "                cv2.imwrite('ROI_{}.jpg'.format(ROI_number), 255*resizing)\n",
    "                cv2.rectangle(copy,(x,y),(x+w,y+h),(0,255,0),5)\n",
    "                #show_images([image])\n",
    "                ROI_number += 1 \n",
    "        else: \n",
    "            for j in all_imgs:\n",
    "                if x >  j[1] and x < j[1]+j[2]-1:\n",
    "                    outside = False\n",
    "            if outside:\n",
    "                    ROI = image[y:y+h, x:x+w]\n",
    "                    resizing = imutils.resize(ROI, width=200)\n",
    "                    charsSegmented.append(ROI)\n",
    "                    cv2.imwrite('ROI_{}.jpg'.format(ROI_number), 255*resizing)\n",
    "                    cv2.rectangle(copy,(x,y),(x+w,y+h),(0,255,0),5)\n",
    "                    #show_images([image])\n",
    "                    ROI_number += 1\n",
    "                    all_imgs.append((ROI,x,w))       \n",
    "        i = i +  1\n",
    "    #sort charchters as the same in the input image       \n",
    "    all_imgs.sort(key=lambda start:start[1],reverse=False) #all_imgs[0]\n",
    "    out_imgs=[]\n",
    "    for char in all_imgs:\n",
    "        out_imgs.append(char[0])\n",
    "    #print(ROI_number)    \n",
    "    return out_imgs #charsSegmented#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5d1c45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tested as better alternative to segmentation, is to directly use OCR\n",
    "# Here we use improved processing ven further to get the characters and in order\n",
    "\n",
    "# Sort characters by their order\n",
    "def Sort_Tuple(listtup): \n",
    "    return listtup.sort(key=lambda y: y[0])\n",
    "\n",
    "def connectedComponentSegmentation(threshAdjusted):\n",
    "    # construct the argument parser and parse the arguments\n",
    "    #ap = argparse.ArgumentParser()\n",
    "    path = 'C:/Users/nadin/OneDrive/Documents/Uni Stuff/Image Processing/PROJECT/result/partition.png'\n",
    "    output = cv2.connectedComponentsWithStats(threshAdjusted.astype(np.uint8), cv2.CV_32S)\n",
    "    # Returns number of labels/compoennts, \n",
    "    (numLabels, labels, stats, centroids) = output\n",
    "    #print('type is ', type(output))\n",
    "    #print(numLabels,'\\n', labels,'\\n', stats,'\\n', centroids)\n",
    "    mask = np.zeros(threshAdjusted.shape, dtype=\"uint8\")\n",
    "    # Label 0 is the background\n",
    "    ListOfTuples = []\n",
    "    for i in range(1, numLabels):\n",
    "        area = stats[i, cv2.CC_STAT_AREA]\n",
    "        x = stats[i, cv2.CC_STAT_LEFT]\n",
    "        labelTuple = (x, area, labels[i],stats[i],centroids[i])\n",
    "        ListOfTuples.append(labelTuple)\n",
    "        componentMask = (labels == i).astype(\"uint8\") * 255\n",
    "        mask = cv2.bitwise_or(mask, componentMask)\n",
    "        mask = np.zeros(threshAdjusted.shape, dtype=\"uint8\")\n",
    "    # Now we have tuple of the character and added the x of them, we will sort on the x\n",
    "    ListOfSortedTuples = []\n",
    "    Sort_Tuple(ListOfTuples)\n",
    "    for i in range(1, len(ListOfTuples)):\n",
    "        componentMask = (labels == i).astype(\"uint8\") * 255\n",
    "        mask = cv2.bitwise_or(mask, componentMask)\n",
    "        x, area, _,_,_ = ListOfTuples[i]\n",
    "        #show_images([mask])\n",
    "        mask = np.zeros(threshAdjusted.shape, dtype=\"uint8\")\n",
    "        ListOfSortedTuples.append(mask)\n",
    "        \n",
    "    return ListOfSortedTuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d8cbf36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    }
   ],
   "source": [
    "reader = easyocr.Reader(['en']) # need to run only once to load model into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a286a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe'\n",
    "\n",
    "def PytesseractRecognition(binary, colored):\n",
    "    textUsingPytesBin = pytesseract.image_to_string(binary)\n",
    "    textUsingPytesCol = pytesseract.image_to_string(colored)\n",
    "    return textUsingPytesBin, textUsingPytesCol\n",
    "\n",
    "def EasyOCR(binary, colored):\n",
    "    textUsingBinary = reader.readtext(binary)\n",
    "    textUsingColored = reader.readtext(colored)\n",
    "    return textUsingBinary, textUsingColored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10e48813",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "directory = r'C:/Users/nadin/OneDrive/Documents/Uni Stuff/Image Processing/PROJECT/result/'\n",
    "pathAsStr = \"C:/Users/nadin/OneDrive/Documents/Uni Stuff/Image Processing/PROJECT/dataset/images/Cars\"\n",
    "def onTest(index):\n",
    "    readImage = cv2.imread(pathAsStr+str(index)+'.png')\n",
    "    extractedPlate, location, a, b, c, d, masked  = preprocessing(readImage)\n",
    "    #show_images([extractedPlate,masked ])\n",
    "    pytesseract.pytesseract.tesseract_cmd = r'C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe'\n",
    "    # We test on 4 different ways\n",
    "    # Using pytesseract on the binary processed vs just cropped colored image \n",
    "    # and using easyOCR on the binary processed vs just cropped colored image  \n",
    "    if (extractedPlate is not None and masked is not None):\n",
    "        textUsingPytesBin, textUsingPytesCol = PytesseractRecognition(extractedPlate, masked)\n",
    "        textUsingBinary, textUsingColored = EasyOCR(extractedPlate, masked)\n",
    "\n",
    "        #print(textUsingPytesBin, '  using pytesseract on binary')\n",
    "        #print(textUsingBinary, ' using easyOCR on binary')\n",
    "        #print(textUsingColored, ' using easyOCR on colored')\n",
    "\n",
    "    if location is not None:\n",
    "        partition = RegionOfInterest(extractedPlate, location, a, b, c, d)\n",
    "        loft = connectedComponentSegmentation(partition)\n",
    "        #if loft is not None:\n",
    "            #print(pytesseract.image_to_string(i) for i in loft)\n",
    "    return textUsingColored\n",
    "    \n",
    "    \n",
    "# 159"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "354e7a96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "directory = r'C:/Users/nadin/OneDrive/Documents/Uni Stuff/Image Processing/PROJECT/result/'\n",
    "pathAsStr = \"C:/Users/nadin/OneDrive/Documents/Uni Stuff/Image Processing/PROJECT/dataset/images/Cars\"\n",
    "index = 147\n",
    "readImage = cv2.imread(pathAsStr+str(index)+'.png')\n",
    "extractedPlate, location, a, b, c,d, colored  = preprocessing(readImage)\n",
    "if location is not None:\n",
    "    partition = RegionOfInterest(extractedPlate, location, a, b, c, d)\n",
    "    ListOfSegChars = segmnetCharactersByContours(partition)\n",
    "    #show_images(ListOfSegChars)\n",
    "    filename = directory+'done'+str(index)+'.png'\n",
    "    cv2.imwrite(filename,partition*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44ea8dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acuraccy(ocr_otput,input_file): # ocr_output-> read from the ocr, input_file-> read from the input file\n",
    "    plates=0 ## counter for whole plates acuraccy\n",
    "    correct=0 \n",
    "    uncorrect=0\n",
    "    illuminate_space=ocr_otput.replace(\" \",\"\") # remove spaces\n",
    "    capital_letter =  illuminate_space.upper() #change lower case to upper\n",
    "    print(input_file,' vs ', capital_letter)\n",
    "    if capital_letter==input_file:## whole matching\n",
    "        plates=plates+1\n",
    "        correct=len(capital_letter)\n",
    "    else:\n",
    "        for i in range(min(len(input_file), len(capital_letter))):\n",
    "            if input_file[i]==capital_letter[i]:\n",
    "                correct=correct+1\n",
    "            else:\n",
    "                uncorrect=uncorrect+1\n",
    "    return plates,correct,uncorrect ## return: \"plates->1 means whole matching, 0 means there's error\",\"correct->number of correct char\",\"uncorrect->number of uncorrect char\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf3ceafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30\n",
      "KLG1CA2555  vs  KLO1CA2555\n",
      "PGMN112  vs  POE1\n",
      "DZI7YXR  vs  DZI7YXR\n",
      "WOR5167  vs  CRSI6K\n",
      "ALR486  vs  AR4BB\n",
      "DZI7YXR  vs  DZI7YXR\n",
      "DL7CN5617  vs  @LZCN5617\n",
      "MH15BD8877  vs  HH15BD8877\n",
      "CHIOOSE  vs  CHIOOSE\n",
      "TAXI  vs  TAXI\n",
      "DL7CN5617  vs  @LZCN5617\n",
      "TN99F2378  vs  TN9962378\n",
      "CZI7KOD  vs  CZI7KOD\n",
      "PGMN112  vs  POE1\n",
      "KAG5MG19G9  vs  KA\n",
      "YWORRY  vs  YPRRY\n",
      "MK-35-32  vs  MK-35-32\n",
      "KAG5MG19G9  vs  KA\n",
      "KLG1CA2555  vs  KLO1CA2555\n",
      "DL8CX4850  vs  DL8CX4850\n",
      "LR33TEE  vs  LR33TEB\n",
      "CZI7KOD  vs  CZI7KOD\n",
      "KL65H4383  vs  KL65H4383\n",
      "MH20EE7598  vs  MH20EE7598\n",
      "EAB0001  vs  EABC\n",
      "DZI7YXR  vs  DZI7YXR\n",
      "MH20EJ0364  vs  NH20EJ0364\n",
      "GOOGLE  vs  GOOGLE\n",
      "GOOGLE  vs  GOOGLE\n",
      "M771276  vs  M:\n",
      "Number of cocorrect chars =  171\n",
      "Number of incorrect chars =  31\n",
      "Number of completely correct plates =  13\n",
      "Accuracy is  84.65346534653466 %. \n"
     ]
    }
   ],
   "source": [
    "def testAndCompare(filepathIndeces, filepathCorrect):\n",
    "    my_file = open(filepathIndeces, \"r\")\n",
    "    content = my_file.read()\n",
    "    content_list = content.split(\",\")\n",
    "    my_file.close()\n",
    "    another = open(filepathCorrect, \"r\")\n",
    "    contentChar = another.read()\n",
    "    charPlate = contentChar.split(\",\")\n",
    "    my_file.close()\n",
    "    indeces = [int(num) for num in content_list]\n",
    "    stringCorrect = []\n",
    "    #print(indeces) # Just to check\n",
    "    #print(charPlate)\n",
    "    print(len(indeces) , len(charPlate))\n",
    "    correctPlates = 0\n",
    "    correctChars = 0 \n",
    "    inCorrectChars = 0\n",
    "    for i in range(len(indeces)):    \n",
    "        x = onTest(indeces[i])\n",
    "        yehemena = x[0][-2]\n",
    "        plates, correct, uncorrect = acuraccy(yehemena,charPlate[i])\n",
    "        correctPlates+=plates\n",
    "        correctChars+=correct\n",
    "        inCorrectChars+=uncorrect\n",
    "    print('Number of cocorrect chars = ',correctChars )\n",
    "    print('Number of incorrect chars = ',inCorrectChars )\n",
    "    print('Number of completely correct plates = ', correctPlates)\n",
    "    print('Accuracy is ', correctChars*100/(correctChars+inCorrectChars),'%. ' )\n",
    "    \n",
    "testAndCompare('TestSetImages.txt', 'carsNum(1).txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16856403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This automates the preprocessing for the whole dataset\n",
    "def automateWhole():\n",
    "    directory = r'C:/Users/nadin/OneDrive/Documents/Uni Stuff/Image Processing/PROJECT/meow/'\n",
    "    countNoRegion = 0\n",
    "    for i in range(433):\n",
    "        pathAsStr = \"C:/Users/nadin/OneDrive/Documents/Uni Stuff/Image Processing/PROJECT/dataset/images/Cars\"\n",
    "        readImage = cv2.imread(pathAsStr+str(i)+'.png')\n",
    "        #show_images([readImage])\n",
    "        extractedPlate, location, x, y, w, h = preprocessing(readImage)\n",
    "        if location is not None:\n",
    "            partition = RegionOfInterest(extractedPlate, location, x, y, w, h)\n",
    "            #ListOfSegChars = segmnetCharactersByContours(partition)\n",
    "            filename = directory+'done'+str(i)+'.png'\n",
    "            cv2.imwrite(filename,partition*255)\n",
    "            SortedChars = connectedComponentSegmentation(partition)\n",
    "            if SortedChars is not None:\n",
    "                for j in range(len(SortedChars)):\n",
    "                    filename = directory+'done/'+str(i)+'7arf'+str(j)+'.png'\n",
    "                    cv2.imwrite(filename,partition*255)\n",
    "        else:\n",
    "            countNoRegion+=1\n",
    "    print(countNoRegion)\n",
    "automateWhole()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61992ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def automate():\n",
    "    directory = r'C:/Users/nadin/OneDrive/Documents/Uni Stuff/Image Processing/PROJECT/result/'\n",
    "    for i in range(433):\n",
    "        pathAsStr = \"C:/Users/nadin/OneDrive/Documents/Uni Stuff/Image Processing/PROJECT/dataset/images/Cars\"\n",
    "        readImage = cv2.imread(pathAsStr+str(i)+'.png')\n",
    "        #show_images([readImage])\n",
    "        extractedPlate, location = preprocessing(readImage)\n",
    "        if location is not None:\n",
    "            partition = RegionOfInterest(extractedPlate, location)\n",
    "            ListOfSegChars = segmnetCharactersByContours(partition)\n",
    "            filename = directory+'done'+str(i)+'.png'\n",
    "            cv2.imwrite(filename,partition*255)\n",
    "automate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125fad03",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = r'C:/Users/nadin/OneDrive/Documents/Uni Stuff/Image Processing/PROJECT/result/'\n",
    "pathAsStr = \"C:/Users/nadin/OneDrive/Documents/Uni Stuff/Image Processing/PROJECT/dataset/images/Cars\"\n",
    "index = 437\n",
    "readImage = cv2.imread(pathAsStr+str(index)+'.png')\n",
    "#show_images([readImage])\n",
    "extractedPlate, location = preprocessing(readImage)\n",
    "if location is not None:\n",
    "    partition = RegionOfInterest(extractedPlate, location)\n",
    "    ListOfSegChars = segmnetCharactersByContours(partition)\n",
    "    filename = directory+'done'+str(index)+'.png'\n",
    "    cv2.imwrite(filename,partition*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b083f477",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GUImode(toDisplay):\n",
    "    sg.theme('DarkAmber')   # Add a touch of color\n",
    "    # All the stuff inside your window.\n",
    "    layout = [  [sg.Text('Some text on Row 1')],\n",
    "                [sg.Text('Enter something on Row 2'), sg.InputText()],\n",
    "                [sg.Button('Ok'), sg.Button('Cancel')] ]\n",
    "\n",
    "    # Create the Window\n",
    "    window = sg.Window('Window Title', layout)\n",
    "    # Event Loop to process \"events\" and get the \"values\" of the inputs\n",
    "    while True:\n",
    "        event, values = window.read()\n",
    "        if event == sg.WIN_CLOSED or event == 'Cancel': # if user closes window or clicks cancel\n",
    "            break\n",
    "        print('You entered ', values[0])\n",
    "\n",
    "    window.close()\n",
    "    \n",
    "GUImode(extractedPlate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526bf1e9",
   "metadata": {},
   "source": [
    "## Garbage and another attemted solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92a0536",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show_images([image, gray_filtered,edged, new_image2, plateRegionOnly ])\n",
    "    \n",
    "\n",
    "'''\n",
    "left_bottom =  location[3][0]\n",
    "right_bottom = location[0][0]\n",
    "left_top =  location[2][0]\n",
    "right_top = location[1][0]\n",
    "print(right_bottom, left_bottom, left_top, right_top )\n",
    "xEnd = max(right_top[0],right_bottom[0]) + 20\n",
    "yEnd = min(right_bottom[1],left_bottom[1]) + 10\n",
    "plateRegionOnly = extractedPlate[yEnd:left_top[1]+10,left_bottom[0]-20:xEnd ]\n",
    "print(yEnd, left_top[1],left_bottom[0]-20,xEnd)\n",
    "print('Plate reg')\n",
    "show_images([plateRegionOnly])\n",
    "print('type is -->', type(plateRegionOnly))\n",
    "'''\n",
    "#print( x, y, w, h)\n",
    "    #left_bottom = vertices[3][0]\n",
    "    #right_bottom = vertices[0][0]\n",
    "    #left_top =  vertices[2][0]\n",
    "    #right_top = vertices[1][0]\n",
    "    \n",
    " '''\n",
    "    for i in range(1, numLabels):\n",
    "        x = stats[i, cv2.CC_STAT_LEFT]\n",
    "        y = stats[i, cv2.CC_STAT_TOP]\n",
    "        w = stats[i, cv2.CC_STAT_WIDTH]\n",
    "        h = stats[i, cv2.CC_STAT_HEIGHT]\n",
    "        area = stats[i, cv2.CC_STAT_AREA]\n",
    "        keepWidth = w > 70 and w < 250\n",
    "        keepHeight = h > 45 and h < 120\n",
    "        keepArea = area < 6000 and area > 1500\n",
    "        # ensure the connected component we are examining passes all\n",
    "        # three tests\n",
    "        if keepArea:\n",
    "            # construct a mask for the current connected component and\n",
    "            # then take the bitwise OR with the mask\n",
    "            #print(\"keeping connected component #'{}'\".format(i))\n",
    "            componentMask = (labels == i).astype(\"uint8\") * 255\n",
    "            mask = cv2.bitwise_or(mask, componentMask)\n",
    "            show_images([mask])\n",
    "            mask = np.zeros(threshAdjusted.shape, dtype=\"uint8\")\n",
    "    '''\n",
    "\n",
    "\n",
    "    \n",
    "    '''\n",
    "    hypotenuse =  math.pow((math.pow((left_bottom[0]-right_bottom[0]), 2) + math.pow((left_bottom[1]-right_bottom[1]), 2)), 0.5)\n",
    "    opposite = right_bottom[1] - left_bottom[1]\n",
    "    rotationAngle = math.asin(opposite/hypotenuse)*57.2958\n",
    "    rotated = imutils.rotate_bound(plate, angle=-rotationAngle)\n",
    "    '''\n",
    "    #show_images([plate])\n",
    "    #show_images([rotated])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42defb80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
